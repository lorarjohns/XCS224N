{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1D convolutional neural network\n",
    "word_embed_size: number of word embedding features ('channels')\n",
    "seq_len: number of time steps/words\n",
    "out_channels: number of filters to apply\n",
    "kernel size: filter window size\n",
    "padding: amount of zero padding to apply to the sequence\n",
    "\n",
    "max: max pooling over time\n",
    "'''\n",
    "\n",
    "batch_size = 16\n",
    "word_embed_size = 4\n",
    "seq_len = 7\n",
    "input = torch.randn(batch_size, word_embed_size, seq_len)\n",
    "conv1 = Conv1d(in_channels=word_embed_size,\n",
    "               out_channels=4,\n",
    "               kernel_size=3,\n",
    "               #padding=1\n",
    "               )\n",
    "hidden1 = conv1(input)\n",
    "hidden2 = torch.max(hidden1, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([16, 4, 7])\ntorch.Size([16, 4, 5])\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.return_types.max(\nvalues=tensor([[ 0.8073,  0.7392,  0.6410,  0.4973],\n        [ 1.0437,  1.9393,  0.5352,  0.5954],\n        [ 1.5676,  1.0931,  0.4885,  0.5392],\n        [ 1.0613,  1.5563,  0.4245,  0.9570],\n        [ 0.7449,  1.3366,  1.1261,  1.2232],\n        [ 0.1474,  0.5716,  0.9041,  0.2372],\n        [ 1.3320,  0.3865,  0.2761,  0.7339],\n        [ 0.2837,  0.8003,  0.7493,  1.2046],\n        [ 0.4842,  0.9318,  0.1813,  0.7009],\n        [ 1.1912,  1.1614,  0.1312,  0.4134],\n        [-0.0257,  0.7380,  0.8102,  0.0210],\n        [ 1.5116,  2.2454,  0.5355,  0.3664],\n        [ 1.0494,  0.9925,  1.0557,  0.1491],\n        [ 0.9173,  1.2709,  0.5128,  0.4038],\n        [ 1.0289,  1.5024,  0.9633,  0.6542],\n        [ 0.5454,  2.0138,  1.3261,  0.5549]], grad_fn=<MaxBackward0>),\nindices=tensor([[3, 4, 3, 2],\n        [3, 2, 4, 1],\n        [4, 0, 0, 3],\n        [0, 3, 1, 3],\n        [3, 4, 3, 0],\n        [2, 4, 1, 3],\n        [4, 2, 1, 3],\n        [0, 3, 2, 4],\n        [4, 1, 4, 0],\n        [3, 2, 4, 1],\n        [0, 0, 0, 4],\n        [4, 0, 1, 3],\n        [1, 0, 1, 2],\n        [0, 0, 2, 4],\n        [1, 2, 4, 1],\n        [3, 1, 3, 0]]))"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "print(input.shape)\n",
    "print(hidden1.shape)\n",
    "hidden2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies a 1D convolution over an input signal composed of several input\n",
    "planes.\n",
    "In the simplest case, the output value of the layer with input size\n",
    "$`(N, C_{\\text{in}}, L)`$ and output $`(N, C_{\\text{out}}, L_{\\text{out}})`$ can be\n",
    "precisely described as:\n",
    "$\n",
    "\\text{out}(N_i, C_{\\text{out}_j}) = \\text{bias}(C_{\\text{out}_j}) +\n",
    "\\sum_{k = 0}^{C_{in} - 1} \\text{weight}(C_{\\text{out}_j}, k)\n",
    "\\star \\text{input}(N_i, k)\n",
    "$\n",
    "where :math:`\\star` is the valid `cross-correlation`_ operator,\n",
    ":math:`N` is a batch size, :math:`C` denotes a number of channels,\n",
    ":math:`L` is a length of signal sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "def generate_sent_masks(enc_hiddens: torch.Tensor, source_lengths: List[int]) -> torch.Tensor:\n",
    "        \"\"\" Generate sentence masks for encoder hidden states.\n",
    "\n",
    "        @param enc_hiddens (Tensor): encodings of shape (b, src_len, 2*h), where b = batch size,\n",
    "                                     src_len = max source length, h = hidden size. \n",
    "        @param source_lengths (List[int]): List of actual lengths for each of the sentences in the batch.\n",
    "        \n",
    "        @returns enc_masks (Tensor): Tensor of sentence masks of shape (b, src_len),\n",
    "                                    where src_len = max source length, h = hidden size.\n",
    "        \"\"\"\n",
    "        enc_masks = torch.zeros(enc_hiddens.size(0), enc_hiddens.size(1), dtype=torch.float)\n",
    "        for e_id, src_len in enumerate(source_lengths):\n",
    "            enc_masks[e_id, src_len:] = 1\n",
    "        return enc_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([5, 18])"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "b = 5 # batch len\n",
    "h = 4 # hidden size\n",
    "\n",
    "source_lengths = torch.from_numpy(np.random.randint(4,20, (b,)))\n",
    "enc_hiddens = torch.Tensor(b, max(source_lengths).item(), 2*h)\n",
    "generate_sent_masks(enc_hiddens, source_lengths).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the original sentence lengths are: tensor([15, 13,  5, 18,  7])\nthe longest sentence in the batch is 18 words\n"
    }
   ],
   "source": [
    "print(f\"the original sentence lengths are: {(source_lengths)}\")\n",
    "print(f\"the longest sentence in the batch is {max(source_lengths).item()} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- initialize mask matrix to batch size x longest sentence\n",
    "- row of mask matrix = position of the input sentence in the list\n",
    "- columns of the row beyond the length of the sentence are set to 1 (masks), because we have padded them to the length of the longest sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.],\n        [0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "generate_sent_masks(enc_hiddens, source_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLEU score:\n",
    "$$ \n",
    "\\dfrac{\\sum_{\\text{ngram} \\in c}  min \\Big(max_{i=1,...,k} \\text{Count}_{r_{i}}(\\text{ngram}), \\text{Count}_c(\\text{ngram})\\Big)}{\\sum_{\\text{ngram}\\in c} \\text{Count}_c (\\text{ngram})}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-9-e965b219ae05>, line 5)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-e965b219ae05>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def bleu(refs,\n",
    "         hypo,\n",
    "         weights=(0.25,0.25,0.25,0.25),\n",
    "):\n",
    "    '''\n",
    "    @param refs: list of reference translations\n",
    "    @param hypo: a hypothesis machine translation\n",
    "    '''\n",
    "\n",
    "def precision(refs, hypo, n):\n",
    "    '''\n",
    "    calculate the ngram precision.\n",
    "    reference word is \"exhausted\" after\n",
    "    the first matching hypothesis.\n",
    "    '''\n",
    "    # count ngrams in hypo\n",
    "    hypo_counts = Counter(ngrams(hypo, n) if len(hypo) >= n else Counter()\n",
    "\n",
    "    # max ngram count over all refs for ngram = n\n",
    "    # iterate over each ngram in each reference\n",
    "    max_counts = {}\n",
    "    for ref in refs:\n",
    "        ref_counts = Counter(ngrams(ref, n)) if len(ref) >= n else Counter()    \n",
    "        for ngram in counts:\n",
    "            max_counts[ngram] = max(max_counts.get(ngram, 0), ref_counts[ngram])\n",
    "    \n",
    "    # min of ngrams in max ref, ngrams in hypo\n",
    "    # iterate over ngrams in hypo\n",
    "    min_max = {ngram: min(max_counts[ngram], count) for ngram, count in hypo_counts.items()}\n",
    "\n",
    "    # sum over all the ngrams\n",
    "    numerator = sum(min_max.values())\n",
    "    denominator = max(1, sum(hypo_counts.values))\n",
    "\n",
    "    return Fraction(numerator, denominator, _normalize=False)\n",
    "\n",
    "def brevity_penalty(ref_lens, hypo_lens):\n",
    "    '''\n",
    "    if hypo is shorter than references, reduce score\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [\"el amor todo lo puede\".split()]\n",
    "r_1 = [\"love can always find a way\".split()]\n",
    "r_2 =[\"love makes anything possible\".split()]\n",
    "c_1 = \"the love can always do\".split()\n",
    "c_2 = \"love can make anything possible\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "([['love', 'can', 'always', 'find', 'a', 'way']], ['the', 'love', 'can', 'always', 'do'])\n0.448437301984003\n([['love', 'can', 'always', 'find', 'a', 'way']], ['love', 'can', 'make', 'anything', 'possible'])\n0.25890539701513365\n([['love', 'makes', 'anything', 'possible']], ['the', 'love', 'can', 'always', 'do'])\n6.6709427497276e-155\n([['love', 'makes', 'anything', 'possible']], ['love', 'can', 'make', 'anything', 'possible'])\n0.3872983346207417\n"
    }
   ],
   "source": [
    "from itertools import product\n",
    "refs = [r_1, r_2]\n",
    "hypos = [c_1, c_2]\n",
    "\n",
    "for i in product(refs, hypos):\n",
    "    a, b = i\n",
    "    print(i)\n",
    "    print(sentence_bleu(a, b, weights=(0.5, 0.5)))\n",
    "#print(corpus_bleu(refs, hypos, weights=(0.5, 0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "c_2\n"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "scores = defaultdict(list)\n",
    "for i, h in enumerate(hypos):\n",
    "    for r in refs:\n",
    "        scores[f'c_{i+1}'].append(sentence_bleu(r, h, weights=(0.5, 0.5)))\n",
    "sum_scores = {k: sum(v) for k,v in scores.items()}\n",
    "print(max(sum_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3\n2\n"
    }
   ],
   "source": [
    "print(len(set(\"love can always find a way\".split()).intersection(set(\"the love can always do\".split()))))\n",
    "print(len(set(\"love can always find a way\".split()).intersection(set(\"love can make anything possible\".split()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitxcs224nvenvc3830852de054796a1ac976dcd799bb1",
   "display_name": "Python 3.7.4 64-bit ('xcs224n': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}