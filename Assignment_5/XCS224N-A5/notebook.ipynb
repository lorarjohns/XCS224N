{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": "\u001b[0;31mSignature:\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m\nsigmoid(input) -> Tensor\n\nApplies the element-wise function :math:`\\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}`\n\nSee :class:`~torch.nn.Sigmoid` for more details.\n\u001b[0;31mFile:\u001b[0m      ~/.pyenv/versions/xcs224n/lib/python3.7/site-packages/torch/nn/functional.py\n\u001b[0;31mType:\u001b[0m      function\n"
    }
   ],
   "source": [
    "F.sigmoid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "text": "\u001b[0;31mInit signature:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m     \nApplies the element-wise function:\n\n.. math::\n    \\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}\n\n\nShape:\n    - Input: :math:`(N, *)` where `*` means, any number of additional\n      dimensions\n    - Output: :math:`(N, *)`, same shape as the input\n\n.. image:: scripts/activation_images/Sigmoid.png\n\nExamples::\n\n    >>> m = nn.Sigmoid()\n    >>> input = torch.randn(2)\n    >>> output = m(input)\n\u001b[0;31mInit docstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n\u001b[0;31mFile:\u001b[0m           ~/.pyenv/versions/xcs224n/lib/python3.7/site-packages/torch/nn/modules/activation.py\n\u001b[0;31mType:\u001b[0m           type\n\u001b[0;31mSubclasses:\u001b[0m     \n"
    }
   ],
   "source": [
    "nn.Sigmoid?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x_{proj} = ReLU(W_{\\text{proj}}x_{\\text{conv_out}} + b_{\\text{proj}}) \\in \\mathbb{R}^{e_{\\text{word}}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$e_{word} = e_{char}\\times m_{word}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 5)\n",
    "y = torch.randn(3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[-0.1355,  0.0165,  0.5267, -2.5321,  0.7066],\n        [ 0.4018, -0.0481, -0.5418, -0.5878,  0.2209],\n        [ 0.5097,  1.5385, -1.0192,  1.1768, -0.3335]])"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[ 0.9137, -0.2251, -0.6497,  2.0474, -0.5563],\n        [-0.2680,  0.2112, -1.0309,  0.4903, -0.4948],\n        [-0.1052,  0.7104, -1.0319, -0.1977, -0.6747]])"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-0d2b02846485>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-0d2b02846485>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    kernel_size =\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "kernel_size = \n",
    "nn.MaxPool1d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_embed_size = 7\n",
    "max_word_length = 10\n",
    "kernel_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(15, 7, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_conv = conv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([15, 70, 6])"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "x_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_conv_relu = F.relu(x_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([15, 70, 6])"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "x_conv_relu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.MaxPool1d(kernel_size=(max_word_length - kernel_size +1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_m = m(x_conv_relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([15, 70, 1])"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "x_m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_m_2 = torch.max(x_m, dim=2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([15, 70])"
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "x_m_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyVocab():\n",
    "    def __init__(self):\n",
    "        self.char2id = json.load(open('./sanity_check_en_es_data/char_vocab_sanity_check.json', 'r'))\n",
    "        self.id2char = {v: k for k,v in self.char2id.items()}\n",
    "        self.unk = self.char2id['<unk>']\n",
    "        self.start_of_word = self.char2id['{']\n",
    "        self.end_of_word = self.char2id['}']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from nmt_model import NMT\n",
    "from vocab import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "--------------------------------------------------------------------------------\nRunning Sanity Checks for Question 1f:  Model Embedding\n--------------------------------------------------------------------------------\nSanity Checks Passed for Question 1f: Model Embedding!\n"
    }
   ],
   "source": [
    "sentence_length = 10\n",
    "max_word_length = 21\n",
    "batch_size = 5\n",
    "embed_size = 3\n",
    "\n",
    "vocab = Vocab.load('./sanity_check_en_es_data/vocab_sanity_check.json')\n",
    "\n",
    "def test_model(sentence_length, batch_size, max_word_length, embed_size):\n",
    "    model = NMT(embed_size=embed_size, hidden_size=3, dropout_rate=0.2, vocab=vocab)\n",
    "    x = torch.zeros(sentence_length, batch_size, max_word_length,   dtype=torch.long)\n",
    "    ME_source = model.model_embeddings_source\n",
    "    output = ME_source.forward(x)\n",
    "    output_expected_size = [sentence_length, batch_size, embed_size]\n",
    "\n",
    "    assert list(output.size()) == output_expected_size, f'Output shape should be:\\n{output_expected_size}, but is:\\n{list(output.size())}'\n",
    "\n",
    "print('-'*80)\n",
    "print('Running Sanity Checks for Question 1f:  Model Embedding')\n",
    "\n",
    "params = (10, 5, 21, 3)\n",
    "test_model(*params)\n",
    "\n",
    "#print('Testing batch size 1')\n",
    "params = (10, 1, 21, 3)\n",
    "test_model(*params)\n",
    "\n",
    "#print('Testing max word length = sentence length')\n",
    "params = (21, 5, 21, 3)\n",
    "test_model(*params)\n",
    "\n",
    "#print('Testing max word length = 20')\n",
    "#params = (10, 5, 20, 3)\n",
    "#test_model(*params)\n",
    "\n",
    "#print('Testing embed_size=1')\n",
    "params = (10, 5, 21, 1)\n",
    "test_model(*params)\n",
    "print('-'*80)\n",
    "print('Sanity Checks Passed for Question 1f: Model Embedding!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([10, 5, 21])"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ModelEmbeddings(\n  (char_embedding_layer): Embedding(96, 50, padding_idx=0)\n  (cnn_layer): CNN(\n    (conv_layer): Conv1d(50, 3, kernel_size=(5,), stride=(1,))\n    (max_pool): MaxPool1d(kernel_size=17, stride=17, padding=0, dilation=1, ceil_mode=False)\n  )\n  (highway_layer): Highway(\n    (projection_layer): Linear(in_features=3, out_features=3, bias=True)\n    (gate_layer): Linear(in_features=3, out_features=3, bias=True)\n    (dropout_layer): Dropout(p=0.3, inplace=False)\n  )\n)"
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "ME_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "torch.Size([10, 5, 3])"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[10, 5, 3]"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "output_expected_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "x[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[0.1239, 0.0000, 0.0000],\n        [0.1239, 0.0000, 0.1509],\n        [0.0000, 0.0000, 0.0000],\n        [0.1239, 0.0000, 0.1509],\n        [0.0000, 0.0000, 0.0000]], grad_fn=<SliceBackward>)"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "output[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nmt_model import NMT\n",
    "from char_decoder import CharDecoder\n",
    "from vocab import Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "EMBED_SIZE = 3\n",
    "HIDDEN_SIZE = 3\n",
    "DROPOUT_RATE = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\"When I die, I want to die like my grandfather who died peacefully in his sleep.\".split(), \"Not screaming like all the passengers in his car.\".split(),\n",
    "\"Always remember that you are absolutely unique.\".split(), \"Just like everyone else.\".split(),\n",
    "\"If toast always lands butter-side down, and cats always land on their feet, what happens if you strap toast on the back of a cat and drop it?\".split(),\n",
    "\"The road to success is always under construction.\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import pad_sents_char\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for sent in sents:\n",
    "    sent = [\"<s>\"] + sent + [\"</s>\"]\n",
    "    data.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(sent) for sent in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sents = sorted(sents, key=lambda x: len(x), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [len(sent) for sent in sorted_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vocab import VocabEntry\n",
    "vocab = VocabEntry(voc)\n",
    "indices = vocab.words2charindices(sorted_sents)\n",
    "\n",
    "padded = pad_sents_char(indices, char_pad_token=0)\n",
    "sents_var = torch.tensor(padded, dtype=torch.long, device='cpu').permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = Counter(\"\".join([\"\".join([w for w in sent]) for sent in sents]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = dict()\n",
    "voc[\"<pad>\"] = 0\n",
    "voc[\"{\"] = 1\n",
    "voc[\"}\"] = 2\n",
    "voc[\"<unk>\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate(chars.keys(), start=4):\n",
    "    voc[i] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyVocab():\n",
    "    def __init__(self):\n",
    "        self.char2id = voc\n",
    "        self.id2char = {v: k for k, v in self.char2id.items()}\n",
    "        self.char_unk = self.char2id['<unk>']\n",
    "        self.start_of_word = self.char2id[\"{\"]\n",
    "        self.end_of_word = self.char2id[\"}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "vocab = DummyVocab()\n",
    "#model = NMT(\n",
    "#    embed_size=EMBED_SIZE,\n",
    "#    hidden_size=HIDDEN_SIZE,\n",
    "#    dropout_rate=DROPOUT_RATE,\n",
    "#    vocab=vocab)\n",
    "#\n",
    "# char_vocab = vocab.tgt\n",
    "\n",
    "decoder = CharDecoder(\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    char_embedding_size=EMBED_SIZE,\n",
    "    target_vocab=vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([ 1, 49, 44,  ...,  0,  0,  0])"
     },
     "metadata": {},
     "execution_count": 96
    }
   ],
   "source": [
    "sents_var[1:].contiguous().view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "CharDecoder(\n  (charDecoder): LSTM(3, 3)\n  (char_output_projection): Linear(in_features=3, out_features=37, bias=True)\n  (decoderCharEmb): Embedding(37, 3, padding_idx=0)\n)"
     },
     "metadata": {},
     "execution_count": 97
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python run.py train --train-src=./en_es_data/train_tiny.es --train-tgt=./en_es_data/train_tiny.en \\\n",
    "        --dev-src=./en_es_data/dev_tiny.es --dev-tgt=./en_es_data/dev_tiny.en --vocab=vocab_tiny_q2.json --batch-size=2 \\\n",
    "        --max-epoch=201 --valid-niter=100"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitxcs224nvenvc3830852de054796a1ac976dcd799bb1",
   "display_name": "Python 3.7.4 64-bit ('xcs224n': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}